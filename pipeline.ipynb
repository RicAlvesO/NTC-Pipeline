{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Traffic Analysis Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.1. Install all needed dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyshark in ./.venv/lib/python3.12/site-packages (0.6)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.12/site-packages (from pyshark) (5.3.0)\n",
      "Requirement already satisfied: termcolor in ./.venv/lib/python3.12/site-packages (from pyshark) (2.5.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from pyshark) (24.1)\n",
      "Requirement already satisfied: appdirs in ./.venv/lib/python3.12/site-packages (from pyshark) (1.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nest_asyncio in ./.venv/lib/python3.12/site-packages (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pymongo in ./.venv/lib/python3.12/site-packages (4.10.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in ./.venv/lib/python3.12/site-packages (from pymongo) (2.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyshark\n",
    "%pip install nest_asyncio\n",
    "%pip install pandas\n",
    "%pip install pymongo\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.2. Allow the notebook to work assynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.3. Setup global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_seed=0\n",
    "base_training_percentage = 60\n",
    "online_training_percentage = 20\n",
    "validation_percentage = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1. Download datasets\n",
    "\n",
    "1.2. Store datasets in a local folder\n",
    "\n",
    "1.3. Select and label the datasets.\n",
    "For each dataset, add it to the list of datasets in a tuple with the format `(dataset_path, dataset_label)`, where:\n",
    "- `dataset_path` is the path to the dataset file\n",
    "- `dataset_label` is the label that should be assigned to the entries, this can be either `normal`,`anomaly` or `unknown`(for unsupervised training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. Import the desired preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessors.pcap_preprocessor import PcapPreprocessor\n",
    "\n",
    "preprocessor = PcapPreprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Load and preprocess the datasets.\n",
    "\n",
    "    This step may depend on the preprocessor used. \n",
    "    The preprocessor should store the data and preprocess the data, providing methods to access it.\n",
    "    In the case of classes that don't store the data in memory, this step can be skipped after the first execution. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(dataset_files) > 0:\n",
    "    preprocessor.load_datasets(dataset_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. Gather all the data in a single dataframe for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = preprocessor.get_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.X. Add vizualization steps here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210000 entries, 0 to 209999\n",
      "Columns: 1204 entries, _id to tls.record_opaque_type\n",
      "dtypes: float64(498), int64(3), object(703)\n",
      "memory usage: 1.9+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(all_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1. Select and import the desired models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OfflineModel' from 'src.models.offline' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moffline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OfflineModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OnlineModel\n\u001b[1;32m      4\u001b[0m model_list \u001b[38;5;241m=\u001b[39m [OfflineModel(), OnlineModel()]\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'OfflineModel' from 'src.models.offline' (unknown location)"
     ]
    }
   ],
   "source": [
    "from src.models.offline import OfflineModel\n",
    "from src.models.online import OnlineModel\n",
    "\n",
    "model_list = [OfflineModel(), OnlineModel()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2. Gather the data for training.\n",
    "\n",
    "When training online models a second dataframe is provided to simulate the online training.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126000 entries, 0 to 125999\n",
      "Columns: 1147 entries, _id to tls.record_size_limit\n",
      "dtypes: float64(472), int64(3), object(672)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 1119 entries, _id to udp._ws_expert_group\n",
      "dtypes: float64(459), int64(3), object(657)\n",
      "memory usage: 358.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "training_data,online_training_data = preprocessor.get_training_data(base_training_percentage, online_training_percentage, True, seed=run_seed)\n",
    "\n",
    "print(training_data.info())\n",
    "print(online_training_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3. Train the models using the offline data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_list:\n",
    "    model.train(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4. Train the online models simulating an online enviorment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_list:\n",
    "    if model.is_online():\n",
    "        model.predict_batch(online_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1. Select and import the desired evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluators.standard_evaluator import Evaluator\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2. Gather the data for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = preprocessor.get_validation_data(validation_percentage,seed=run_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3. Get the predictions from all models into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header\n",
    "header = ['expected']\n",
    "for model in model_list:\n",
    "    header.append(model.get_name())\n",
    "validation_results = [header]\n",
    "\n",
    "# Results\n",
    "for index, row in validation_data.iterrows():\n",
    "    line = [row['label']]\n",
    "    unlabelled_row = row.drop('label')\n",
    "    for model in model_list:\n",
    "        line.append(model.predict(unlabelled_row))\n",
    "    validation_results.append(line)\n",
    " \n",
    "df = pd.DataFrame(validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4. Evaluate the models using their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluator.evaluate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.5. Analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
