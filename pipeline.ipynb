{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Traffic Analysis Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyshark in ./.venv/lib/python3.12/site-packages (0.6)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.12/site-packages (from pyshark) (5.3.0)\n",
      "Requirement already satisfied: termcolor in ./.venv/lib/python3.12/site-packages (from pyshark) (2.5.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from pyshark) (24.1)\n",
      "Requirement already satisfied: appdirs in ./.venv/lib/python3.12/site-packages (from pyshark) (1.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nest_asyncio in ./.venv/lib/python3.12/site-packages (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pymongo in ./.venv/lib/python3.12/site-packages (4.10.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in ./.venv/lib/python3.12/site-packages (from pymongo) (2.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyshark\n",
    "%pip install nest_asyncio\n",
    "%pip install pandas\n",
    "%pip install pymongo\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow the notebook to work assynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "run_seed=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_files = [('data/allow/normal_1.pcap','allow'),('data/deny/normal_DDoS_1.pcap','deny'),('data/deny/injection_normal1.pcap','deny')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the desired preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessors.pcap_preprocessor import PcapPreprocessor\n",
    "\n",
    "preprocessor = PcapPreprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the datasets into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.load_datasets(dataset_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Preprocess the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.preprocess_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Partition the dataframe into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_training_percentage = 60\n",
    "online_training_percentage = 20\n",
    "validation_percentage = 20\n",
    "\n",
    "training_data, online_training_data = preprocessor.get_training_data(base_training_percentage, online_training_percentage, True, seed=run_seed)\n",
    "validation_data, labels = preprocessor.get_validation_data(validation_percentage,seed=run_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Columns: 936 entries, _id to dns.unsolicited\n",
      "dtypes: float64(375), int64(3), object(558)\n",
      "memory usage: 128.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 18000 to 23999\n",
      "Columns: 936 entries, _id to dns.unsolicited\n",
      "dtypes: float64(375), int64(3), object(558)\n",
      "memory usage: 42.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 24000 to 29999\n",
      "Columns: 935 entries, _id to dns.unsolicited\n",
      "dtypes: float64(375), int64(3), object(557)\n",
      "memory usage: 42.8+ MB\n",
      "None\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 6000 entries, 24000 to 29999\n",
      "Series name: label\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "6000 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 47.0+ KB\n",
      "None\n",
      "                            _id                           dataset  \\\n",
      "24000  67351a3309d842ac6bb9ab2d          data/allow/normal_1.pcap   \n",
      "24001  67351a3309d842ac6bb9c147          data/allow/normal_1.pcap   \n",
      "24002  67351afa09d842ac6bba140f      data/deny/normal_DDoS_1.pcap   \n",
      "24003  67351afa09d842ac6bb9fb5a      data/deny/normal_DDoS_1.pcap   \n",
      "24004  67351af209d842ac6bb9dfbe  data/deny/injection_normal1.pcap   \n",
      "\n",
      "       sll.pkttype  sll.hatype  sll.halen        sll.src_eth sll.unused  \\\n",
      "24000            4           1          6  a4:91:b1:1e:58:9e      00:00   \n",
      "24001            4           1          6  a4:91:b1:1e:58:9c      00:00   \n",
      "24002            3           1          6  00:0c:29:b8:b1:74      00:00   \n",
      "24003            3           1          6  a4:91:b1:1e:57:90      00:00   \n",
      "24004            3           1          6  00:0c:29:18:73:fe      00:00   \n",
      "\n",
      "      sll.ltype            eth.dst   eth.dst_resolved  ...  \\\n",
      "24000    0x0003  05:00:00:53:04:d2  05:00:00:53:04:d2  ...   \n",
      "24001    0x0003  03:00:03:a1:04:d2  03:00:03:a1:04:d2  ...   \n",
      "24002       NaN                NaN                NaN  ...   \n",
      "24003       NaN                NaN                NaN  ...   \n",
      "24004       NaN                NaN                NaN  ...   \n",
      "\n",
      "       tls.pkcs1_publicexponent tls.x509af_extensions  \\\n",
      "24000                       NaN                   NaN   \n",
      "24001                       NaN                   NaN   \n",
      "24002                       NaN                   NaN   \n",
      "24003                       NaN                   NaN   \n",
      "24004                       NaN                   NaN   \n",
      "\n",
      "      tls.x509af_extension_element tls.x509af_extension_id  \\\n",
      "24000                          NaN                     NaN   \n",
      "24001                          NaN                     NaN   \n",
      "24002                          NaN                     NaN   \n",
      "24003                          NaN                     NaN   \n",
      "24004                          NaN                     NaN   \n",
      "\n",
      "      tls.x509ce_subjectkeyidentifier tls.x509af_algorithmidentifier_element  \\\n",
      "24000                             NaN                                    NaN   \n",
      "24001                             NaN                                    NaN   \n",
      "24002                             NaN                                    NaN   \n",
      "24003                             NaN                                    NaN   \n",
      "24004                             NaN                                    NaN   \n",
      "\n",
      "       tls.ber_bitstring_padding tls.x509af_encrypted http.location  \\\n",
      "24000                        NaN                  NaN           NaN   \n",
      "24001                        NaN                  NaN           NaN   \n",
      "24002                        NaN                  NaN           NaN   \n",
      "24003                        NaN                  NaN           NaN   \n",
      "24004                        NaN                  NaN           NaN   \n",
      "\n",
      "      dns.unsolicited  \n",
      "24000             NaN  \n",
      "24001             NaN  \n",
      "24002             NaN  \n",
      "24003             NaN  \n",
      "24004             NaN  \n",
      "\n",
      "[5 rows x 935 columns]\n",
      "24000    allow\n",
      "24001    allow\n",
      "24002     deny\n",
      "24003     deny\n",
      "24004     deny\n",
      "Name: label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(training_data.info())\n",
    "print(online_training_data.info())\n",
    "print(validation_data.info())\n",
    "print(labels.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select the desired models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.offline import OfflineModel\n",
    "from src.models.online import OnlineModel\n",
    "\n",
    "model_list = [OfflineModel(), OnlineModel()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train the models according to their type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_list:\n",
    "    model.train(training_data)\n",
    "    if model.is_online():\n",
    "        model.predict_batch(online_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the predictions from the models into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header\n",
    "header = ['expected']\n",
    "for model in model_list:\n",
    "    header.append(model.get_name())\n",
    "validation_results = [header]\n",
    "\n",
    "# Results\n",
    "for index, row in validation_data.iterrows():\n",
    "    line = [row['label']]\n",
    "    for model in model_list:\n",
    "        line.append(model.predict(row))\n",
    "    validation_results.append(line)\n",
    " \n",
    "df = pd.DataFrame(validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the desired evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluators.standard_evaluator import Evaluator\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluate the models using the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluator.evaluate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
